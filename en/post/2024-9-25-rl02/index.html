<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
<!-- head.html --><!-- meta.html -->
<meta charset="utf-8"/>
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Bellman Function详解 | Ashhhi</title>
<meta content="[Ash]" name="author"/>
<meta content="本系列为强化学习的学习笔记，本章讲解对State value，Bellman equation的理解。" name="description"/>
<meta content="Reinforcement Learning" name="keywords"/>
<link href="https://ashhhi.life/en/post/2024-9-25-rl02/" rel="canonical"/>
<link href="https://ashhhi.life/img/potato-logo.svg" rel="icon" type="image/svg+xml"/>
<meta content="Ashhhi" name="apple-mobile-web-app-title"/>
<link href="https://example.com/@username" rel="me"/>
<!-- js.html -->
<script crossorigin="anonymous" defer="" integrity="sha384-d4QeYigDeuSJIVAgWwT2Rb+9lSo4UbGYS2fPnRMy4XUtE0RcB69UCYInyjdDOGGz" src="https://ashhhi.life/js/hugo-brewm.min.js"></script><!-- css.html -->
<link crossorigin="anonymous" href="https://ashhhi.life/css/hugo-brewm.min.css" integrity="sha256-qxhTSARMhFq9RJGWfX8v7xD44LkrTvuppQBWTUMBsfo=" rel="stylesheet"/>
<!-- css/inline.html -->
<style>
         
        body {max-width: 786px; margin: auto; padding: 2rem;}
        img {max-width: 86vw;}
    </style>
<link href="https://example.com/@username" rel="me"/>
<!-- katex.html -->
<link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" rel="stylesheet"/>
<script crossorigin="anonymous" defer="" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"></script>
<script crossorigin="anonymous" defer="" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" onload="renderMathInElement(document.body);" src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js"></script>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.getElementById('main-article'), {
                delimiters: [
                    {left: '$', right: '$', display: false},
                    {left: '$$', right: '$$', display: true},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\begin{equation}", right: "\end{equation}", display: true},
                    {left: "\begin{align}", right: "\end{align}", display: true},
                ],
                throwOnError : false
            });
        });
    </script>
</head>
<body>
<!-- header.html -->
<header class="pagewidth">
<div aria-hidden="true" class="background" id="background-header">
<div class="grain" hidden=""></div>
</div>
<nav aria-label="Bypass">
<a aria-label="Skip to Main Content" href="#content" id="to-content">
<span>Skip to Main Content</span>
<kbd aria-hidden="true" class="key">c</kbd>
<span aria-hidden="true" class="screening"></span>
</a>
</nav>
<a aria-description="Homepage" aria-label="Ashhhi" href="https://ashhhi.life/en/" id="logo">
<img alt="Ashhhi" id="logomark--dark" src="https://ashhhi.life/img/potato-logo.svg"/>
<img alt="Ashhhi" id="logomark" src="https://ashhhi.life/img/potato-logo.svg"/>
<!-- logotype.html --><svg aria-label="Ashhhi" id="logotype" version="1.1" width="168pt" xmlns="http://www.w3.org/2000/svg">
<text id="logotype__text" x="0" y="19.5pt">Ashhhi</text>
</svg>
</a>
<details class="presentation" id="top-nav">
<summary class="on-deck">
<span class="t">Navigation</span>
<span class="menu-icon" role="presentation"></span>
</summary>
<nav aria-label="Top" tabindex="-1">
<!-- menu.html -->
<!-- search.html -->
<details class="presentation js-details" id="has-search" name="on-deck">
<summary accesskey="q" aria-keyshortcuts="q" aria-labelledby="search-label" class="on-deck srm">
<span class="t srt" id="search-label">Search</span>
</summary>
<!-- pagefind.html -->
<div class="on-hull" id="search">
<div class="screening js-cgpn" role="presentation"></div>
</div>
<script src="https://ashhhi.life/pagefind/pagefind-ui.js" type="text/javascript"></script>
<script>
        let pageFindInitialized = false;
        const initPageFind = function(event) {
            if (!pageFindInitialized) {
                new PagefindUI({
                    element: "#search",
                    showImages: false,
                    translations: {
                        placeholder: "Search"
                    }
                });
                
                const pFInput = document.querySelector('.pagefind-ui__search-input');
                if (pFInput) {
                    pFInput.setAttribute('aria-label', pFInput.getAttribute('placeholder'));
                }
                pageFindInitialized = true;
                document.removeEventListener('DOMContentLoaded', initPageFind);
            }
        };
        document.addEventListener('DOMContentLoaded', initPageFind);
    </script>
<noscript class="on-hull" id="has-search-fallback">
<!-- duckduckgo.html -->
<form action="//duckduckgo.com/" aria-label="" class="form on-plank" id="duckduckgo" name="x" role="search">
<input name="sites" type="hidden" value="ashhhi.life"/>
<input name="kh" type="hidden" value="1"/>
<input name="kn" type="hidden" value="1"/>
<input name="kac" type="hidden" value="1"/>
<input class="ldots form__input" name="q" placeholder="Search" role="searchbox" type="search"/>
<button aria-label="Search" class="form__button" type="submit">
<img alt="" aria-hidden="true" role="presentation" src="https://duckduckgo.com/assets/logo_header.v109.svg"/>
</button>
</form>
<div class="screening js-cgpn" role="presentation"></div>
</noscript>
</details>
<!-- menu.html -->
<!-- i18n.html -->
</nav>
<div aria-hidden="true" class="screening js-cpn" id="top-nav-screen" role="presentation"></div>
</details>
</header>
<!-- [main] baseof.html -->
<main class="post" id="page">
<!-- main/header.html -->
<header class="pagewidth">
<menu class="srm"><button aria-label="Print" class="hide" id="print-button" onclick="window.print()">
<span class="t srt" role="tooltip">Print</span>
</button>
<a aria-label="Share" href="#share" id="navigatorShare" role="button">
<span class="t srt" role="tooltip">Share</span>
</a>
<button aria-label="Copy URL" class="hide" id="copyPermalink" onclick="navigator.clipboard.writeText(window.location.href)">
<span class="t srt" id="copy" role="tooltip">Copy URL</span>
<span id="isCopying" style="display: none;">Copying...</span>
<span id="copyText" style="display: none;">Copy URL</span>
</button>
</menu>
<!-- nav.html -->
<details aria-expanded="true" class="presentation" id="has-breadcrumb" open="">
<summary id="breadcrumb" tabindex="-1">
<span>Breadcrumb</span>
</summary>
<nav aria-labelledby="breadcrumb">
<ul class="breadcrumb" role="presentation">
<!-- breadcrumb.html -->
<li>
<a aria-current="true" href="https://ashhhi.life/en/post/">Post
            </a>
</li>
<li>
<a aria-current="page" href="" tabindex="-1">Bellman Function详解
        </a>
</li>
</ul>
</nav>
</details>
</header>
<div id="top" role="presentation">
</div>
<article aria-labelledby="title" class="pagewidth" data-pagefind-body="" id="main-article" role="document">
<header aria-labelledby="title" class="textwidth">
<!-- title.html -->
<hgroup data-bionread-safe="">
<h1 data-pagefind-meta="title" id="title">Bellman Function详解</h1>
<p class="subtitle" role="doc-subtitle">本系列为强化学习的学习笔记，本章讲解对State value，Bellman equation的理解。</p>
</hgroup>
<div class="textsw author" id="doc-author"><span>[Ash]</span>
</div>
<!-- timestamp.html-->
<div class="date-has-label">
<time class="doc-publish-date" data-time-label="Published on" datetime="2024-09-25T00:00:00+00:00">September 25, 2024</time><time class="doc-lastmod-date" data-time-label="Modified on" datetime="2025-03-21T00:07:13+08:00">March 21, 2025</time>
</div>
</header>
<!-- audio.html -->
<section aria-labelledby="Title" data-bionread-safe="" id="content">
<p>$$
\begin{align*}
v_\pi(s) &amp;= \sum_{a \in \mathcal{A}} \pi(a|s) \sum_{r \in \mathcal{R}}p(r|s,a)r + \lambda \sum_{s’ \in \mathcal{S}}v_\pi(s’)\sum_{a \in \mathcal{A}} p[s’|s,a]\pi(a|s) \\
&amp;= \sum_{a \in \mathcal{A}}\pi(a|s)[\sum_{r \in \mathcal{R}}p(r|s,a)r+\lambda \sum_{s’ \in \mathcal{S}}v_\pi(s’)p[s’|s,a]]
\end{align*}
$$</p>
<p>​参考：<a href="https://www.bilibili.com/video/BV1sd4y167NS?p=1&amp;vd_source=88e57e827a3a63fa6e3de1856178e929">西湖大学赵世钰老师的【强化学习的数学原理】</a></p>
<hr/>
<h1 id="return-和-state-value">Return 和 State value</h1>
<p>如上一章所讲，强化学习就是学习一个好的<code>Policy</code>的过程，那如何量化这个Policy是不是好的呢，于是引出了<code>Reward</code>的概念。但是Reward只能体现智能体在某一个状态下可以做的行为的好坏，而并不能体现出全局的思想，而策略可以看作一系列行为的集合，包括在每一个状态下怎么去行为。上一章还写到了<code>Return</code>的概念，也就是一条路径上所有奖励的和。</p>
<p>如何计算Return？还是拿网格游戏举例子，如图定义了一个2x2的地图，初始状态是\(s_1\)，我们需要找到一条道路去到\(s_4\)，我们定义黄色的方格为禁区，如果到达禁区，奖励为-1，到达空白区域奖励为0，到达目的地奖励为1。</p>
<p><img alt="" src="https://ashhhi.life/img/2024-9-25-RL02/1.png"/></p>
<p>我们设定智能体会一直运作下去，到了target space也不停下来。如图定义了三种不同的策略，箭头代表了每一个状态下的行为，那么状态\(s_1\)在前两个策略下的Return为（用\(G\)来表示，利用无穷等比数列的求和公式）：</p>
<p>$$
G_1 =
\begin{cases}
\begin{align*}
0 + 1 \cdot \lambda + 1 \cdot \lambda^2 + 1 \cdot \lambda^3 + \ldots &amp;= \frac{\lambda}{1 - \lambda} \\
-1 + 1 \cdot \lambda + 1 \cdot \lambda^2 + 1 \cdot \lambda^3 + \ldots &amp;= -1 + \frac{\lambda}{1 - \lambda}
\end{align*}
\end{cases}, \quad \lambda \in (0,1)
$$</p>
<p>Return并不单纯只是路径上所有Reward之和相加，而是加入\(\lambda\)作为权重，目的是为了限制Return不会无休止地膨胀下去，并且我们可以通过控制其大小来控制模型的“远视”或者“近视”，如果\(\lambda\)偏向1，那么模型将会看得更远，如果偏向0，那么权重衰减得将会很快，模型会更看重前面几个状态的抉择。</p>
<p>但是这是在策略固定的情况下，也就是说我们知道在每一个状态，有且只有一个行为可以选择。</p>
<p>然而，在真正的学习过程中，策略是不固定的，也就是说每一个状态下都有多个行为可以选择，我们需要求得最优解，即每个状态下走哪一条路的概率最高，于是我们引出了<code>状态值（State value）</code>的概念。很简单，其实状态值就是该状态下可能的所有路径的Return的期望。所以在前两种策略下，\(s_1\)的State value就等于它的Return，而第三种策略下，其状态值为：</p>
<p>$$
v_1 = 0.5 * \frac{\lambda}{1-\lambda} + 0.5 * (-1 + \frac{\lambda}{1-\lambda}) = -0.5 + \frac{\lambda}{1-\lambda}
$$</p>
<p>通过对比三种策略下\(s_1\)的状态值，我们可以得出第一种是最高的，因此第一种策略是最优策略，直观上我们也可以看出来，因为它避免了智能体进入禁区。因此这也是为什么状态值可以成为量化策略的一个指标。</p>
<h1 id="贝尔曼方程">贝尔曼方程</h1>
<h2 id="简单理解">简单理解</h2>
<p><img alt="" src="https://ashhhi.life/img/2024-9-25-RL02/2.png"/></p>
<p>考虑一个特殊的策略，如图形成了一个循环的策略，那么我们可以求得每一个状态下的状态值为：</p>
<p>$$
v_1 = r_1 + \lambda r_2 + \lambda^2 r_3 + … \\
v_2 = r_2 + \lambda r_3 + \lambda^2 r_4 + … \\
v_3 = r_3 + \lambda r_4 + \lambda^2 r_1 + … \\
v_4 = r_4 + \lambda r_1 + \lambda^2 r_2 + … \\
$$</p>
<p>进一步简化可以得到：
$$
v_1 = r_1 + \lambda v_2 \\
v_2 = r_2 + \lambda v_3 \\
v_3 = r_3 + \lambda v_4 \\
v_4 = r_4 + \lambda v_1 \\
$$</p>
<p>四个方程四个未知数（\(r\)看作是已知的），其实是可以把\(v\)解出来的。这里体现出了自举（bootstrapping）的思想，即从自身求自身的值。当我们把这些式子化作一个线性矩阵方程便会很好理解：</p>
<p>$$
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix}=
\begin{pmatrix}
r_1 \\ r_2 \\ r_3 \\ r_4
\end{pmatrix}+
\lambda
\begin{pmatrix}
0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0  \\ 0 &amp; 0 &amp; 0 &amp; 1  \\ 1 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix} \tag{1}
$$</p>
<p>化简得\(\vec{v} = \vec{r} + \lambda P \vec{v} \)， 这其实就是<code>贝尔曼方程</code>在这种简单策略下的的简单表达。</p>
<h2 id="复杂形式">复杂形式</h2>
<h3 id="公式推导">公式推导</h3>
<p>还是先理清几个定义，我们假设在状态\(t\)的路径为：</p>
<p>$$
S_t \overset{A_t}{\longrightarrow} S_{t+1}, R_{t+1} \overset{A_{t+1}}{\longrightarrow} S_{t+2}, R_{t+2} …
$$</p>
<ul>
<li>\(S_t\)：每个状态</li>
<li>\(A_t\)：从\(S_t\)到\(S_{t+1}\)所需采取的行为</li>
<li>\(R_{t+1}\)：采取行为\(A_t\)到达状态\(S_{t+1}\)所能得到的奖励</li>
</ul>
<p>可以得到这条路径的Return为：</p>
<p>$$
G_t = R_{t+1} + \lambda R_{t+2} + \lambda^2 R_{t+3}… = R_{t+1} + \lambda G_{t+1} \tag{2}
$$</p>
<p>那么这个状态的状态值便是在策略\(\pi\)下所有Return的期望，这就是<code>状态值函数</code>，有些地方把V大写：
$$
\begin{align*}
V_\pi(s) = v_\pi(s) &amp;= \mathbb{E}[G_t|S_t=s] \\
&amp;= \mathbb{E}[R_{t+1} + \lambda G_{t+1}|S_t=s] \\
&amp;= \mathbb{E}[R_{t+1}|S_t=s] + \lambda \mathbb{E}[G_{t+1}|S_t=s]
\end{align*}
$$</p>
<p>这里有两项，我们分别对这两项进行计算，先定义三个集合：</p>
<ul>
<li>\(\mathcal{S}\)：所有的状态</li>
<li>\(\mathcal{R}\)：所有的奖励</li>
<li>\(\mathcal{A}\)：所有的动作</li>
</ul>
<p>首先是第一项：</p>
<p>$$
\begin{align*}
\mathbb{E}[R_{t+1}|S_t=s] &amp;= \sum_{a \in \mathcal{A}}\pi(a|s)\mathbb{E}[R_{t+1}|S_t=s, A_t=a] \\
&amp;= \sum_{a \in \mathcal{A}} \pi(a|s) \sum_{r \in \mathcal{R}}p(r|s,a)r
\end{align*}
$$</p>
<p>其中\(\pi(a|s)\)为在策略\(\pi\)下，在状态\(s\)，选择行为\(a\)的概率。</p>
<p>接着来计算第二项，其中第二步用了马尔可夫决策过程的无记忆性的特征：</p>
<p>$$
\begin{align*}
\mathbb{E}[G_{t+1}|S_t=s] &amp;= \sum_{s’ \in \mathcal{S}}\mathbb{E}[G_{t+1}|S_t=s, S_{t+1}=s’]p[s’|s] \\
&amp;= \sum_{s’ \in \mathcal{S}}\mathbb{E}[G_{t+1}|S_{t+1}=s’]p[s’|s] \\
&amp;= \sum_{s’ \in \mathcal{S}}\mathbb{E}[G_{t+1}|S_{t+1}=s’]\sum_{a \in \mathcal{A}} p[s’|s,a]\pi(a|s) \\
&amp;= \sum_{s’ \in \mathcal{S}}v_\pi(s’)\sum_{a \in \mathcal{A}} p[s’|s,a]\pi(a|s)
\end{align*}
$$</p>
<p>最后把二者合并起来就形成了贝尔曼方程的规范版本：</p>
<p>$$
\begin{align*}
v_\pi(s) &amp;= \sum_{a \in \mathcal{A}} \pi(a|s) \sum_{r \in \mathcal{R}}p(r|s,a)r + \lambda \sum_{s’ \in \mathcal{S}}v_\pi(s’)\sum_{a \in \mathcal{A}} p[s’|s,a]\pi(a|s) \\
&amp;= \sum_{a \in \mathcal{A}}\pi(a|s)[\sum_{r \in \mathcal{R}}p(r|s,a)r+\lambda \sum_{s’ \in \mathcal{S}}v_\pi(s’)p[s’|s,a]]
\end{align*} \tag{3}
$$</p>
<h3 id="example">Example</h3>
<p>看起来很复杂，其实只是因为这是一个通用的公式，如果举个简单的例子，就很清晰了。还是拿本章最开始的第一个那个例子来说，假设我们选择第一个策略，来求取它的\(v_\pi(s=1)\)，其实就是\(v_1\)。</p>
<p>这里策略\(\pi\)规定了只能往下走，那么只有\(\pi(a=down|s=1)=1\)，并且向下走只能到状态\(s_3\)，所以只有\(p[s_3|s_1,a=down]=1\)。因此原式等于：</p>
<p>$$
\begin{align*}
v_1 &amp;= \sum_{a \in \mathcal{A}}\pi(a|s)[\sum_{r \in \mathcal{R}}p(r|s,a)r+\lambda \sum_{s’ \in \mathcal{S}}v_\pi(s’)p[s’|s,a]] \\
&amp;= \sum_{r \in \mathcal{R}}p(r|s_1,a=down)r + \lambda v_\pi(s_3) \\
&amp;= 0 + \lambda v_\pi(s_3)
\end{align*}
$$</p>
<p>就得到了之前的简单情况下的结果。</p>
<h2 id="矩阵化">矩阵化</h2>
<p>以上所写的贝尔曼方程形式都是单状态形式的，因此如果我们有\(n\)个状态的话我们就可以有\(n\)个方程，就可以写成一个矩阵形式，还是先把（3）式括号合并化简为：</p>
<p>$$
v_\pi(s) = r_\pi(s) + \lambda \sum_{s’ \in \mathcal(S)} p_\pi(s’|s)v_\pi(s’)
$$</p>
<p>有\(n\)个这样的式子，因此我们可以写成这种形式，其中i=1，2，3，…，n。
$$
v_\pi(s_i) = r_\pi(s_i) + \lambda \sum_{s_j \in \mathcal(S)} p_\pi(s_j|s_i)v_\pi(s_j)
$$</p>
<p>进一步我们可以进一步化简，直接用一个矩阵代替，为什么能这么化简呢？这里可以参考（1）式理解：</p>
<p>$$
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix}=
\begin{pmatrix}
r_1 \\ r_2 \\ r_3 \\ r_4
\end{pmatrix}+
\lambda
\begin{pmatrix}
p_\pi(s_1|s_1) &amp; p_\pi(s_2|s_1) &amp; p_\pi(s_3|s_1) &amp; p_\pi(s_4|s_1) \\
p_\pi(s_1|s_2) &amp; p_\pi(s_2|s_2) &amp; p_\pi(s_3|s_2) &amp; p_\pi(s_4|s_2) \\
p_\pi(s_1|s_3) &amp; p_\pi(s_2|s_3) &amp; p_\pi(s_3|s_3) &amp; p_\pi(s_4|s_3) \\
p_\pi(s_1|s_4) &amp; p_\pi(s_2|s_4) &amp; p_\pi(s_3|s_4) &amp; p_\pi(s_4|s_4)
\end{pmatrix}
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix}
$$
$$
v_\pi = r_\pi + \lambda P_\pi v_\pi \tag{3}
$$</p>
<h2 id="求解">求解</h2>
<p>通过贝尔曼方程我们可以求解到每一个状态的状态值，通过（3）式我们可以很容易得到:
$$
v_\pi = (I-\lambda P)^{-1}r_\pi
$$
但是当状态空间足够大，\(P\)矩阵的维度将会非常大，对其求逆会消耗大量的计算资源，因此更常用的求解方式是迭代式算法，该算法会生成一个序列 \(v_0,v_1,v_2,…,v_n\)，\(v_0\)是一个初始化的值，通过这个随机值我们可以根据（2）式以此计算出后面的状态值。</p>
<p>迭代式算法有一个重要的特征，也就是当\(n\)趋近于无穷的时候，\(v_{n+1}\)和\(v_n\)基本上相同，其原因这里不做交代。</p>
<h1 id="action-value">Action value</h1>
<p>很简单，行为值指的就是每一个状态下采取具体的某一个动作能得到的Return, 其实也就是Q-learning中大Q值，也叫<code>动作值函数</code>：</p>
<p>$$
Q_\pi(s,a) = q_\pi(s,a) = \mathbb{E}[G_t|S_t=t,A_t=a] \tag{4}
$$</p>
<p>通过行为值的比较，我们可以确定该状态下应该选择具体哪一个行为，一个状态下所有的行为值加起来就等于这个状态的状态值。</p>
<p>根据Return的定义（2）式，我们（4）式展开可以得到：</p>
<p>$$
q_\pi(s,a) = \mathbb{E}[r + \lambda G_{t+1}|S_t=t,A_t=a] \tag{5}
$$</p>
</section>
<footer>
<nav aria-label="Tags" id="keywords">
<span>Tag: </span>
<!-- terms.html -->
<ul class="inline" role="presentation">
<li><a href="https://ashhhi.life/en/tags/reinforcement-learning/">Reinforcement Learning</a></li>
</ul>
</nav>
</footer>
</article>
<hr class="hide" style="margin: 1in 0;"/>
<div class="pagewidth" data-pagefind-ignore="all" id="contentinfo" role="contentinfo">
<!-- related.html -->
<nav aria-label="You might also like" id="related"><strong class="section-title">You might also like</strong>
<ol>
<li><a href="https://ashhhi.life/en/post/2024-9-23-rl01/">强化学习中的基本概念以及马尔可夫决策</a></li>
</ol>
</nav>
<!-- colophon.html -->
<div aria-live="polite" id="colophon" style="display: none;">
<strong class="section-title">Colophon</strong>
<div>
<div aria-label="QR code" id="qr" role="img"></div>
<div class="verbose">
<div aria-label="Bellman Function详解" class="has-aria-label-top"><span>https://ashhhi.life/en/post/2024-9-25-rl02/</span></div>
<div><span>This page is built on: </span><time datetime="2025-10-11T11:39:59+08:00">2025-10-11 11:39</time></div>
<div><span>This page is accessed on: </span><time id="time-stamp"></time></div><div><span>Powered by </span><a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo</a> <a aria-label="Hugo 0.145.0" href="https://github.com/gohugoio/hugo/releases/tag/v0.145.0" rel="noopener" target="_blank">v0.145.0</a> &amp; <a href="https://github.com/foxihd/hugo-brewm" rel="noopener" target="_blank">hugo-brewm</a>.</div>
</div>
</div>
</div>
<!-- history.html -->
<div id="has-timeline">
<strong class="section-title">Redaction History</strong>
<ol aria-label="Redaction History">
<li>
<time datetime="2024-09-25T00:00:00+00:00">September 25, 2024</time>
<span>(Published)</span>
</li>
<li>
<time datetime="2025-03-21T00:07:13+08:00">March 21, 2025</time>
<span>(Modified)</span>
</li>
</ol>
<p>Some information might changes over time, we keep redaction up to date.</p>
</div>
</div>
<div class="pagewidth">
</div>
<!-- main/footer.html -->
</main>
<!-- footer.html -->
<footer class="pagewidth" id="body-footer" style="display: none;">
<div aria-hidden="true" class="background hide" id="background-footer" role="presentation">
<div class="grain" hidden=""></div>
</div>
<div id="focusMode"></div>
<!-- a11y.html --><details aria-haspopup="true" aria-labelledby="has-a11y-summary" class="presentation js-details hide" id="has-a11y" name="on-deck">
<summary accesskey="a" aria-keyshortcuts="a" id="has-a11y-summary">
<span> Accessibility</span>
<kbd aria-hidden="true" class="key">a</kbd>
</summary>
<!-- a11y console -->
<fieldset aria-label="Accessibility" data-i18n-baselinestretch="Baseline Stretch" data-i18n-bionread="BionRead Mode" data-i18n-close="Close" data-i18n-colorpalette="Color Palette" data-i18n-colorsettings="Color Settings" data-i18n-contrast="Contrast" data-i18n-dark="Dark" data-i18n-darkmode="Dark Mode" data-i18n-defaultcolor="Default" data-i18n-defaultcontrast="Default" data-i18n-deuteranopia="Deuteranopia" data-i18n-focusmode="Focus Mode" data-i18n-fontsize="Font Size" data-i18n-lesscontrast="Low" data-i18n-light="Light" data-i18n-menucontrols="Accessibility Menu Controls" data-i18n-monochrome="Monochrome" data-i18n-morecontrast="High" data-i18n-nolocalstorage="LocalStorage is not available in your browser. Settings won't be saved." data-i18n-opendyslexic="Use OpenDyslexic Font" data-i18n-optimizesr="Screen Reader Optimization" data-i18n-optimizesrdesc="Optimize display and resources for screen reader users who navigate with a pointer device." data-i18n-protanopia="Protanopia" data-i18n-reset="Reset" data-i18n-save="Save" data-i18n-tritanopia="Tritanopia" id="a11y" role="region">
</fieldset>
<div aria-hidden="true" class="screening js-cpn" role="presentation"></div>
</details>
<div class="sri" id="useBionRead"></div>
<!-- [top] bypass block -->
<nav aria-label="Bypass">
<a accesskey="c" aria-keyshortcuts="c" aria-label="To Content Top" class="srm" href="#top" id="to-top" title="To Content Top">
<span class="t srt">To Content Top</span>
<kbd aria-hidden="true" class="key">c</kbd>
</a>
</nav>
</footer>
<!-- [post] single.html -->
<div hidden="" id="bionReadSnapshot"></div>
<!-- [background] baseof.html -->
<div aria-hidden="true" id="background-body" role="presentation"></div>
</body></html>