

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 




      <title>Bellman Function详解 - Ashhhi</title>

  <meta name="description" content="本系列为强化学习的学习笔记，本章讲解对State value，Bellman equation的理解。">
  <meta name="author" content="Ashhhi"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Ashhhi - 杂记",
    
    "url": "http:\/\/localhost:1313\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "http:\/\/localhost:1313\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "http:\/\/localhost:1313\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "http:\/\/localhost:1313\/post\/2024-9-25-rl02\/",
          "name": "Bellman function详解"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Ashhhi"
  },
  "headline": "Bellman Function详解",
  "description" : "本系列为强化学习的学习笔记，本章讲解对State value，Bellman equation的理解。\n",
  "inLanguage" : "en",
  "wordCount":  2895 ,
  "datePublished" : "2024-09-25T00:00:00\u002b00:00",
  "dateModified" : "2024-09-25T00:00:00\u002b00:00",
  "image" : "http:\/\/localhost:1313\/img\/avatar.jpg",
  "keywords" : [ "Reinforcement Learning" ],
  "mainEntityOfPage" : "http:\/\/localhost:1313\/post\/2024-9-25-rl02\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "http:\/\/localhost:1313\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "http:\/\/localhost:1313\/img\/avatar.jpg",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="Bellman Function详解" />
<meta property="og:description" content="本系列为强化学习的学习笔记，本章讲解对State value，Bellman equation的理解。">
<meta property="og:image" content="http://localhost:1313/img/avatar.jpg" />
<meta property="og:url" content="http://localhost:1313/post/2024-9-25-rl02/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Ashhhi - 杂记" />

  <meta name="twitter:title" content="Bellman Function详解" />
  <meta name="twitter:description" content="本系列为强化学习的学习笔记，本章讲解对State value，Bellman equation的理解。">
  <meta name="twitter:image" content="http://localhost:1313/img/avatar.jpg" />
  <meta name="twitter:card" content="summary_large_image" />
  
  <link
  rel="icon"
  type="image/svg+xml"
  href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🥔</text></svg>"
/>
  <meta name="generator" content="Hugo 0.134.2">
  <link rel="alternate" href="http://localhost:1313/index.xml" type="application/rss+xml" title="Ashhhi - 杂记"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="http://localhost:1313/css/main-nodark.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="http://localhost:1313/css/highlight.min.css" /><link rel="stylesheet" href="http://localhost:1313/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">




  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://localhost:1313/">Ashhhi - 杂记</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/page/about/">About</a>
            </li>
          
        

        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Ashhhi - 杂记" href="http://localhost:1313/">
            <img class="avatar-img" src="http://localhost:1313/img/avatar.jpg" alt="Ashhhi - 杂记" />
           
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Bellman Function详解</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on September 25, 2024
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;6&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;2895&nbsp;words
  
  

  
  
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      
      
        
          <nav id="TableOfContents">
  <ul>
    <li><a href="#return-和-state-value">Return 和 State value</a></li>
    <li><a href="#贝尔曼方程">贝尔曼方程</a>
      <ul>
        <li><a href="#简单理解">简单理解</a></li>
        <li><a href="#复杂形式">复杂形式</a>
          <ul>
            <li><a href="#公式推导">公式推导</a></li>
            <li><a href="#example">Example</a></li>
          </ul>
        </li>
        <li><a href="#矩阵化">矩阵化</a></li>
        <li><a href="#求解">求解</a></li>
      </ul>
    </li>
    <li><a href="#action-value">Action value</a></li>
  </ul>
</nav> 
        
      


      <article role="main" class="blog-post">
        <p>本系列为强化学习的学习笔记，本章讲解对State value，Bellman equation的理解。</p>
<p>​参考：<a href="https://www.bilibili.com/video/BV1sd4y167NS?p=1&amp;vd_source=88e57e827a3a63fa6e3de1856178e929">西湖大学赵世钰老师的【强化学习的数学原理】</a></p>
<hr>
<h1 id="return-和-state-value">Return 和 State value</h1>
<p>如上一章所讲，强化学习就是学习一个好的<code>Policy</code>的过程，那如何量化这个Policy是不是好的呢，于是引出了<code>Reward</code>的概念。但是Reward只能体现智能体在某一个状态下可以做的行为的好坏，而并不能体现出全局的思想，而策略可以看作一系列行为的集合，包括在每一个状态下怎么去行为。上一章还写到了<code>Return</code>的概念，也就是一条路径上所有奖励的和。</p>
<p>如何计算Return？还是拿网格游戏举例子，如图定义了一个2x2的地图，初始状态是\(s_1\)，我们需要找到一条道路去到\(s_4\)，我们定义黄色的方格为禁区，如果到达禁区，奖励为-1，到达空白区域奖励为0，到达目的地奖励为1。</p>
<p><img src="/img/2024-9-25-RL02/1.png" alt=""></p>
<p>我们设定智能体会一直运作下去，到了target space也不停下来。如图定义了三种不同的策略，箭头代表了每一个状态下的行为，那么状态\(s_1\)在前两个策略下的Return为（用\(G\)来表示，利用无穷等比数列的求和公式）：</p>
<p>$$
G_1 =
\begin{cases}
\begin{align*}
0 + 1 \cdot \lambda + 1 \cdot \lambda^2 + 1 \cdot \lambda^3 + \ldots &amp;= \frac{\lambda}{1 - \lambda} \\
-1 + 1 \cdot \lambda + 1 \cdot \lambda^2 + 1 \cdot \lambda^3 + \ldots &amp;= -1 + \frac{\lambda}{1 - \lambda}
\end{align*}
\end{cases}, \quad \lambda \in (0,1)
$$</p>
<p>Return并不单纯只是路径上所有Reward之和相加，而是加入\(\lambda\)作为权重，目的是为了限制Return不会无休止地膨胀下去，并且我们可以通过控制其大小来控制模型的“远视”或者“近视”，如果\(\lambda\)偏向1，那么模型将会看得更远，如果偏向0，那么权重衰减得将会很快，模型会更看重前面几个状态的抉择。</p>
<p>但是这是在策略固定的情况下，也就是说我们知道在每一个状态，有且只有一个行为可以选择。</p>
<p>然而，在真正的学习过程中，策略是不固定的，也就是说每一个状态下都有多个行为可以选择，我们需要求得最优解，即每个状态下走哪一条路的概率最高，于是我们引出了<code>状态值（State value）</code>的概念。很简单，其实状态值就是该状态下可能的所有路径的Return的期望。所以在前两种策略下，\(s_1\)的State value就等于它的Return，而第三种策略下，其状态值为：</p>
<p>$$
v_1 = 0.5 * \frac{\lambda}{1-\lambda} + 0.5 * (-1 + \frac{\lambda}{1-\lambda}) = -0.5 + \frac{\lambda}{1-\lambda}
$$</p>
<p>通过对比三种策略下\(s_1\)的状态值，我们可以得出第一种是最高的，因此第一种策略是最优策略，直观上我们也可以看出来，因为它避免了智能体进入禁区。因此这也是为什么状态值可以成为量化策略的一个指标。</p>
<h1 id="贝尔曼方程">贝尔曼方程</h1>
<h2 id="简单理解">简单理解</h2>
<p><img src="/img/2024-9-25-RL02/2.png" alt=""></p>
<p>考虑一个特殊的策略，如图形成了一个循环的策略，那么我们可以求得每一个状态下的状态值为：</p>
<p>$$
v_1 = r_1 + \lambda r_2 + \lambda^2 r_3 + &hellip; \\
v_2 = r_2 + \lambda r_3 + \lambda^2 r_4 + &hellip; \\
v_3 = r_3 + \lambda r_4 + \lambda^2 r_1 + &hellip; \\
v_4 = r_4 + \lambda r_1 + \lambda^2 r_2 + &hellip; \\
$$</p>
<p>进一步简化可以得到：
$$
v_1 = r_1 + \lambda v_2 \\
v_2 = r_2 + \lambda v_3 \\
v_3 = r_3 + \lambda v_4 \\
v_4 = r_4 + \lambda v_1 \\
$$</p>
<p>四个方程四个未知数（\(r\)看作是已知的），其实是可以把\(v\)解出来的。这里体现出了自举（bootstrapping）的思想，即从自身求自身的值。当我们把这些式子化作一个线性矩阵方程便会很好理解：</p>
<p>$$
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix}=
\begin{pmatrix}
r_1 \\ r_2 \\ r_3 \\ r_4
\end{pmatrix}+
\lambda
\begin{pmatrix}
0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0  \\ 0 &amp; 0 &amp; 0 &amp; 1  \\ 1 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix} \tag{1}
$$</p>
<p>化简得\(\vec{v} = \vec{r} + \lambda P \vec{v} \)， 这其实就是<code>贝尔曼方程</code>在这种简单策略下的的简单表达。</p>
<h2 id="复杂形式">复杂形式</h2>
<h3 id="公式推导">公式推导</h3>
<p>还是先理清几个定义，我们假设在状态\(t\)的路径为：</p>
<p>$$
S_t \overset{A_t}{\longrightarrow} S_{t+1}, R_{t+1} \overset{A_{t+1}}{\longrightarrow} S_{t+2}, R_{t+2} &hellip;
$$</p>
<ul>
<li>\(S_t\)：每个状态</li>
<li>\(A_t\)：从\(S_t\)到\(S_{t+1}\)所需采取的行为</li>
<li>\(R_{t+1}\)：采取行为\(A_t\)到达状态\(S_{t+1}\)所能得到的奖励</li>
</ul>
<p>可以得到这条路径的Return为：</p>
<p>$$
G_t = R_{t+1} + \lambda R_{t+2} + \lambda^2 R_{t+3}&hellip; = R_{t+1} + \lambda G_{t+1} \tag{2}
$$</p>
<p>那么这个状态的状态值便是在策略\(\pi\)下所有Return的期望：
$$
\begin{align*}
v_\pi(s) &amp;= \mathbb{E}[G_t|S_t=s] \\
&amp;= \mathbb{E}[R_{t+1} + \lambda G_{t+1}|S_t=s] \\
&amp;= \mathbb{E}[R_{t+1}|S_t=s] + \lambda \mathbb{E}[G_{t+1}|S_t=s]
\end{align*}
$$</p>
<p>这里有两项，我们分别对这两项进行计算，先定义三个集合：</p>
<ul>
<li>\(\mathcal{S}\)：所有的状态</li>
<li>\(\mathcal{R}\)：所有的奖励</li>
<li>\(\mathcal{A}\)：所有的动作</li>
</ul>
<p>首先是第一项：</p>
<p>$$
\begin{align*}
\mathbb{E}[R_{t+1}|S_t=s] &amp;= \sum_{a \in \mathcal{A}}\pi(a|s)\mathbb{E}[R_{t+1}|S_t=s, A_t=a] \\
&amp;= \sum_{a \in \mathcal{A}} \pi(a|s) \sum_{r \in \mathcal{R}}p(r|s,a)r
\end{align*}
$$</p>
<p>其中\(\pi(a|s)\)为在策略\(\pi\)下，在状态\(s\)，选择行为\(a\)的概率。</p>
<p>接着来计算第二项，其中第二步用了马尔可夫决策过程的无记忆性的特征：</p>
<p>$$
\begin{align*}
\mathbb{E}[G_{t+1}|S_t=s] &amp;= \sum_{s&rsquo; \in \mathcal{S}}\mathbb{E}[G_{t+1}|S_t=s, S_{t+1}=s&rsquo;]p[s&rsquo;|s] \\
&amp;= \sum_{s&rsquo; \in \mathcal{S}}\mathbb{E}[G_{t+1}|S_{t+1}=s&rsquo;]p[s&rsquo;|s] \\
&amp;= \sum_{s&rsquo; \in \mathcal{S}}\mathbb{E}[G_{t+1}|S_{t+1}=s&rsquo;]\sum_{a \in \mathcal{A}} p[s&rsquo;|s,a]\pi(a|s) \\
&amp;= \sum_{s&rsquo; \in \mathcal{S}}v_\pi(s&rsquo;)\sum_{a \in \mathcal{A}} p[s&rsquo;|s,a]\pi(a|s)
\end{align*}
$$</p>
<p>最后把二者合并起来就形成了贝尔曼方程的规范版本：</p>
<p>$$
\begin{align*}
v_\pi(s) &amp;= \sum_{a \in \mathcal{A}} \pi(a|s) \sum_{r \in \mathcal{R}}p(r|s,a)r + \lambda \sum_{s&rsquo; \in \mathcal{S}}v_\pi(s&rsquo;)\sum_{a \in \mathcal{A}} p[s&rsquo;|s,a]\pi(a|s) \\
&amp;= \sum_{a \in \mathcal{A}}\pi(a|s)[\sum_{r \in \mathcal{R}}p(r|s,a)r+\lambda \sum_{s&rsquo; \in \mathcal{S}}v_\pi(s&rsquo;)p[s&rsquo;|s,a]]
\end{align*} \tag{3}
$$</p>
<h3 id="example">Example</h3>
<p>看起来很复杂，其实只是因为这是一个通用的公式，如果举个简单的例子，就很清晰了。还是拿本章最开始的第一个那个例子来说，假设我们选择第一个策略，来求取它的\(v_\pi(s=1)\)，其实就是\(v_1\)。</p>
<p>这里策略\(\pi\)规定了只能往下走，那么只有\(\pi(a=down|s=1)=1\)，并且向下走只能到状态\(s_3\)，所以只有\(p[s_3|s_1,a=down]=1\)。因此原式等于：</p>
<p>$$
\begin{align*}
v_1 &amp;= \sum_{a \in \mathcal{A}}\pi(a|s)[\sum_{r \in \mathcal{R}}p(r|s,a)r+\lambda \sum_{s&rsquo; \in \mathcal{S}}v_\pi(s&rsquo;)p[s&rsquo;|s,a]] \\
&amp;= \sum_{r \in \mathcal{R}}p(r|s_1,a=down)r + \lambda v_\pi(s_3) \\
&amp;= 0 + \lambda v_\pi(s_3)
\end{align*}
$$</p>
<p>就得到了之前的简单情况下的结果。</p>
<h2 id="矩阵化">矩阵化</h2>
<p>以上所写的贝尔曼方程形式都是单状态形式的，因此如果我们有\(n\)个状态的话我们就可以有\(n\)个方程，就可以写成一个矩阵形式，还是先把（3）式括号合并化简为：</p>
<p>$$
v_\pi(s) = r_\pi(s) + \lambda \sum_{s&rsquo; \in \mathcal(S)} p_\pi(s&rsquo;|s)v_\pi(s&rsquo;)
$$</p>
<p>有\(n\)个这样的式子，因此我们可以写成这种形式，其中i=1，2，3，&hellip;，n。
$$
v_\pi(s_i) = r_\pi(s_i) + \lambda \sum_{s_j \in \mathcal(S)} p_\pi(s_j|s_i)v_\pi(s_j)
$$</p>
<p>进一步我们可以进一步化简，直接用一个矩阵代替，为什么能这么化简呢？这里可以参考（1）式理解：</p>
<p>$$
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix}=
\begin{pmatrix}
r_1 \\ r_2 \\ r_3 \\ r_4
\end{pmatrix}+
\lambda
\begin{pmatrix}
p_\pi(s_1|s_1) &amp; p_\pi(s_2|s_1) &amp; p_\pi(s_3|s_1) &amp; p_\pi(s_4|s_1) \\
p_\pi(s_1|s_2) &amp; p_\pi(s_2|s_2) &amp; p_\pi(s_3|s_2) &amp; p_\pi(s_4|s_2) \\
p_\pi(s_1|s_3) &amp; p_\pi(s_2|s_3) &amp; p_\pi(s_3|s_3) &amp; p_\pi(s_4|s_3) \\
p_\pi(s_1|s_4) &amp; p_\pi(s_2|s_4) &amp; p_\pi(s_3|s_4) &amp; p_\pi(s_4|s_4)
\end{pmatrix}
\begin{pmatrix}
v_1 \\ v_2 \\ v_3 \\ v_4
\end{pmatrix}
$$
$$
v_\pi = r_\pi + \lambda P_\pi v_\pi \tag{3}
$$</p>
<h2 id="求解">求解</h2>
<p>通过贝尔曼方程我们可以求解到每一个状态的状态值，通过（3）式我们可以很容易得到:
$$
v_\pi = (I-\lambda P)^{-1}r_\pi
$$
但是当状态空间足够大，\(P\)矩阵的维度将会非常大，对其求逆会消耗大量的计算资源，因此更常用的求解方式是迭代式算法，该算法会生成一个序列 \(v_0,v_1,v_2,&hellip;,v_n\)，\(v_0\)是一个初始化的值，通过这个随机值我们可以根据（2）式以此计算出后面的状态值。</p>
<p>迭代式算法有一个重要的特征，也就是当\(n\)趋近于无穷的时候，\(v_{n+1}\)和\(v_n\)基本上相同，其原因这里不做交代。</p>
<h1 id="action-value">Action value</h1>
<p>很简单，行为值指的就是每一个状态下采取具体的某一个动作能得到的Return：</p>
<p>$$
q_\pi(s,a) \dot{=} \mathbb{E}[G_t|S_t=t,A_t=a] \tag{4}
$$</p>
<p>通过行为值的比较，我们可以确定该状态下应该选择具体哪一个行为，一个状态下所有的行为值加起来就等于这个状态的状态值。</p>
<p>其实这里的\(q\)也就是Q-learning中Q值，根据Return的定义（2）式，我们（4）式展开可以得到：</p>
<p>$$
q_\pi(s,a) \dot{=} \mathbb{E}[r + \lambda G_{t+1}|S_t=t,A_t=a] \tag{5}
$$</p>
<p>利用贝尔曼最优方程，当智能体在状态\(s\)执行动作\(a\)后。。。。。。（记得补充贝尔曼最优方程）</p>

        
          <div class="blog-tags">
            
              
              <a href="http://localhost:1313/tags/reinforcement-learning/">Reinforcement Learning</a>&nbsp;
            
          </div>
        

        

        
          
            
          

          
                  <h4 class="see-also">See also</h4>
                  <ul>
                
                
                    <li><a href="/post/2024-9-23-rl01/">强化学习中的基本概念以及马尔可夫决策</a></li>
                
              </ul>

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="http://localhost:1313/post/2024-9-23-rl01/" data-toggle="tooltip" data-placement="top" title="强化学习中的基本概念以及马尔可夫决策">&larr; Previous Post</a>
            </li>
          
          
        </ul>
      


      
      
      
      
      
      
        <script src="https://giscus.app/client.js"
        data-repo="ashhhi/hugoblogtalks"
        data-repo-id="R_kgDOLgjUJw"
        data-category="Announcements"
        data-category-id="DIC_kwDOLgjUJ84CimSM"
        data-mapping="title"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="gruvbox_light"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
        </script>
      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
		
		  <a href="mailto:shijunshen424@gmail.com" title="Email me">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://github.com/ashhhi" title="GitHub">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://open.spotify.com/user/31qjiuhfme47s27qrx6366ruvmjq" title="Spotify">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-spotify fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://telegram.me/ashsjs424" title="Telegram">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-telegram fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              Ashhhi
            
          

          &nbsp;&bull;&nbsp;&copy;
          2024

          
            &nbsp;&bull;&nbsp;
            <a href="http://localhost:1313/">Ashhhi - 杂记</a>
          
          
            &nbsp;&bull;&nbsp;
            <small class="fas fa-clock"></small>
            <span id="sitetime"></span>
            <script language=javascript>
                function siteTime(){
                    window.setTimeout("siteTime()", 1000);
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth()+1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(2024,3,13,0,0,0);  
                    var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
                    var diff = t2-t1;
                    var diffYears = Math.floor(diff/years);
                    var diffDays = Math.floor((diff/days)-diffYears*365);
                    var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
                    var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
                    var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
                    document.getElementById("sitetime").innerHTML="<small>"+diffYears+" y "+diffDays+" d "+diffHours+" h "+diffMinutes+" m "+diffSeconds+" s"+"</small>"; 
                }
                siteTime();
            </script>
          

          &nbsp;&bull;&nbsp;
          <small class="fas fa-users"></small>
          <script async src="/js/busuanzi.pure.mini.js"></script>
          <small>
              <span id="busuanzi_value_site_pv"></span>
          </small>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.134.2</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="http://localhost:1313/js/main.js"></script>
<script src="http://localhost:1313/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="http://localhost:1313/js/load-photoswipe.js"></script>














    
  </body>
</html>

